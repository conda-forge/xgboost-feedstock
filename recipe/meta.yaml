{% set version = "2.1.4" %}
{% set build_number = 1 %}

{% set string_prefix = "cuda" ~ (cuda_compiler_version | replace('.', '')) if (cuda_compiler_version or "None") != "None" else "cpu" %}

package:
  name: xgboost-split
  version: {{ version }}

source:
  url: https://github.com/dmlc/xgboost/releases/download/v{{ version }}/xgboost-{{ version }}.tar.gz
  sha256: b6ce5870d03cc1233cad5ff8460f670a2aff78625adfb578c0b9eec3b8b88406
  patches:
    # xgboost patches
    - patches/0001-Enable-latest-libcxx-on-MacOS.patch                # [osx]
    - patches/0002-Remove-nvidia-nccl-cu12-from-pyproject.toml.patch
    - patches/0003-Mark-wheels-as-any-platform-compatible.patch

build:
  number: {{ build_number }}
  # Skip if `python_min` is undefined. This ensures re-rendering picks it up.
  #
  # Skip CUDA 12.6 in favor of 12.8. This package supports CUDA Compatibility.
  # So packages built with CUDA 12.8 work for all CUDA 12.x versions.
  # ref: https://docs.nvidia.com/deploy/cuda-compatibility/index.html
  #
  # Windows CUDA 11.8 fails due to a compilation error
  # xref: https://github.com/conda-forge/xgboost-feedstock/issues/173
  skip: true  # [(python_min is undefined) or (cuda_compiler_version == "12.6") or (win and cuda_compiler_version == "11.8")]

requirements:
  build:
    - {{ compiler('c') }}
    - {{ compiler('cxx') }}
    - {{ compiler('cuda') }}           # [cuda_compiler != "None" and cuda_compiler_version != "None"]
    - {{ compiler('m2w64_c') }}        # [win]
    - {{ compiler('m2w64_cxx') }}      # [win]
    - {{ stdlib('c') }}
    - {{ stdlib('m2w64_c') }}          # [win]
    - m2-sed                           # [win]
    - cmake
    - llvm-openmp  # [osx]
    - libgomp      # [linux or win]
    - ninja
  host:
    ############################################################################################
    # Pin to CCCL 2.7 to avoid build issues in older or newer CCCLs.                           #
    #                                                                                          #
    # xref: https://github.com/conda-forge/xgboost-feedstock/pull/219#issuecomment-2738813028  #
    ############################################################################################
    - cccl =2.7             # [cuda_compiler != "None"]
    - nccl                  # [linux and cuda_compiler != "None"]

outputs:
  - name: libxgboost
    script: >-
      {{ "install-libxgboost.sh" if not win else "install-win-wrapper.bat" }}
    build:
      activate_in_script: true
      string: {{ string_prefix }}_h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      ignore_run_exports_from:
        - {{ compiler('cuda') }}  # [cuda_compiler != "None"]
      missing_dso_whitelist:
        # Conda-build raises the missing `R.dll` linkage erroneously.
        # xref: https://github.com/conda/conda-build/pull/4786
        - '*/R.dll'         # [win]
        # Conda-build raises the missing `ld64.so.2` linkage erroneously.
        # xref: https://github.com/conda/conda-build/issues/5403
        - $RPATH/ld64.so.2  # [ppc64le]
    requirements:
      build:
        - {{ compiler('c') }}
        - {{ compiler('cxx') }}
        - {{ compiler('cuda') }}  # [cuda_compiler != "None"]
        - {{ stdlib('c') }}
        - git
        - cmake
        - make
        - llvm-openmp  # [osx]
        - libgomp      # [linux or win]
      host:
        - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler != "None"]
        - nccl                                      # [linux and cuda_compiler != "None"]
        - libgomp                                   # [win]
      run:
        - __cuda                                                    # [cuda_compiler != "None"]
        - {{ pin_compatible("cuda-version", lower_bound="11.2") }}  # [cuda_compiler == "nvcc"]
        - {{ pin_compatible("cuda-version", min_pin="x") }}         # [cuda_compiler == "cuda-nvcc"]
        - libgomp                                                   # [win]
    test:
      commands:
        - test -f "${PREFIX}/lib/libxgboost${SHLIB_EXT}"                  # [unix]
        - if not exist %LIBRARY_PREFIX%\mingw-w64\bin\xgboost.dll exit 1  # [win]

  - name: _py-xgboost-mutex
    version: 2.0
    build:
      string: {{ "cpu" if cuda_compiler == "None" else "gpu" }}_0
    test:
      commands:
        - exit 0

  - name: py-xgboost
    script: >-
      {{ "install-py-xgboost.sh" if not win else "install-win-wrapper.bat" }}
    build:
      noarch: python
      string: {{ string_prefix }}_pyh{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      script_env:
        # Workaround an upstream conda-build issue w/pip & `outputs` by setting env vars manually.
        # xref: https://github.com/conda/conda-build/issues/3993
        - PIP_NO_BUILD_ISOLATION=False
        - PIP_NO_DEPENDENCIES=True
        - PIP_IGNORE_INSTALLED=True
        - PIP_CACHE_DIR=pip_cache
        - PIP_NO_INDEX=True
    requirements:
      build:                                                   # [build_platform != target_platform]
        - python {{ python_min }}                              # [build_platform != target_platform]
        - cross-python_{{ target_platform }} {{ python_min }}  # [build_platform != target_platform]
      host:
        - {{ pin_subpackage('_py-xgboost-mutex', exact=True) }}
        - {{ pin_subpackage('libxgboost', max_pin='x.x.x') }}
        - libxgboost =*={{ string_prefix }}_h*_{{ PKG_BUILDNUM }}
        - python {{ python_min }}
        - hatchling >=1.12.1
        - packaging >=21.3
        - pip
      run:
        - {{ pin_subpackage('_py-xgboost-mutex', exact=True) }}
        - {{ pin_subpackage('libxgboost', max_pin='x.x.x') }}
        - libxgboost =*={{ string_prefix }}_h*_{{ PKG_BUILDNUM }}
        - python >={{ python_min }}
        - numpy
        - scipy
        - scikit-learn
        - __cuda  # [cuda_compiler != "None"]
    test:
      requires:
        - python {{ python_min }}
        - pip
      imports:
        - xgboost
      commands:
        - pip check
      script: test-py-xgboost.py

  - name: py-xgboost-cpu
    build:
      noarch: python
      skip: true  # [cuda_compiler != "None"]
    requirements:
      host:
        - python {{ python_min }}
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - py-xgboost =*={{ string_prefix }}_pyh*_{{ PKG_BUILDNUM }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - py-xgboost =*={{ string_prefix }}_pyh*_{{ PKG_BUILDNUM }}
    test:
      requires:
        - python {{ python_min }}
      imports:
        - xgboost

  - name: py-xgboost-gpu
    build:
      noarch: python
      skip: true  # [cuda_compiler == "None"]
    requirements:
      host:
        - python {{ python_min }}
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - py-xgboost =*={{ string_prefix }}_pyh*_{{ PKG_BUILDNUM }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - py-xgboost =*={{ string_prefix }}_pyh*_{{ PKG_BUILDNUM }}
        - __cuda  # [cuda_compiler != "None"]
    test:
      requires:
        - python {{ python_min }}
      imports:
        - xgboost

  - name: xgboost
    build:
      noarch: python
      string: {{ string_prefix }}_pyh{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
    requirements:
      host:
        - python {{ python_min }}
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - py-xgboost =*={{ string_prefix }}_pyh*_{{ PKG_BUILDNUM }}
      run:
        - python >={{ python_min }}
        - {{ pin_subpackage('py-xgboost', exact=True) }}
        - py-xgboost =*={{ string_prefix }}_pyh*_{{ PKG_BUILDNUM }}
        - __cuda  # [cuda_compiler != "None"]
    test:
      requires:
        - python {{ python_min }}
      imports:
        - xgboost

  - name: _r-xgboost-mutex
    version: 2.0
    build:
      string: {{ "cpu" if cuda_compiler == "None" else "gpu" }}_0
    test:
      commands:
        - exit 0

  - name: r-xgboost
    script: >-
      {{ "install-r-xgboost.sh" if not win else "install-r-xgboost.bat" }}
    build:
      skip: true  # [r_base in ("4.1", "4.2")]
      string: {{ string_prefix }}_r{{ r_base | replace('.', '') }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}
      rpaths:
        - lib/R/lib
      missing_dso_whitelist:
        # Conda-build raises the missing `ld64.so.2` linkage erroneously.
        # xref: https://github.com/conda/conda-build/issues/5403
        - $RPATH/ld64.so.2  # [ppc64le]
    requirements:
      build:
        - {{ compiler('c') }}              # [unix]
        - {{ compiler('cxx') }}            # [unix]
        - {{ compiler('m2w64_c') }}        # [win]
        - {{ compiler('m2w64_cxx') }}      # [win]
        - {{ stdlib('c') }}                # [unix]
        - {{ stdlib('m2w64_c') }}          # [win]
        - llvm-openmp                      # [osx]
        - libgomp                          # [linux or win]
        - m2-bash                          # [win]
        - git
        - make
        - cmake
        - ninja
        - cross-r-base {{ r_base }}        # [build_platform != target_platform]
        - r-base                           # [build_platform != target_platform]
        - r-matrix                         # [build_platform != target_platform]
        - r-data.table                     # [build_platform != target_platform]
        - r-magrittr                       # [build_platform != target_platform]
        - r-jsonlite                       # [build_platform != target_platform]
        - r-knitr                          # [build_platform != target_platform]
      host:
        - {{ pin_subpackage('_r-xgboost-mutex', exact=True) }}
        - {{ pin_subpackage('libxgboost', max_pin='x.x.x') }}
        - libgomp                                                  # [win]
        - libxgboost =*={{ string_prefix }}_h*_{{ PKG_BUILDNUM }}
        - r-base
        - r-matrix
        - r-data.table
        - r-magrittr
        - r-jsonlite
        - r-knitr
      run:
        - {{ pin_subpackage('_r-xgboost-mutex', exact=True) }}
        - {{ pin_subpackage('libxgboost', max_pin='x.x.x') }}
        - libgomp                                                  # [win]
        - libxgboost =*={{ string_prefix }}_h*_{{ PKG_BUILDNUM }}
        - r-base
        - r-matrix
        - r-data.table
        - r-magrittr
        - r-jsonlite
        - __cuda  # [cuda_compiler != "None"]
    test:
      requires:
        - r-base
      files:
        - test-r-xgboost.r
      commands:
        - Rscript test-r-xgboost.r  # [not win]

  - name: r-xgboost-cpu
    build:
      skip: true  # [r_base in ("4.1", "4.2") or cuda_compiler != "None"]
    requirements:
      host:
        - r-base
        - {{ pin_subpackage('r-xgboost', exact=True) }}
        - r-xgboost =*={{ string_prefix }}_r*h*_{{ PKG_BUILDNUM }}
      run:
        - r-base
        - {{ pin_subpackage('r-xgboost', exact=True) }}
        - r-xgboost =*={{ string_prefix }}_r*h*_{{ PKG_BUILDNUM }}
    test:
      requires:
        - r-base
      commands:
        - $R -e "library('xgboost')"           # [unix]
        - "\"%R%\" -e \"library('xgboost')\""  # [win]

  - name: r-xgboost-gpu
    build:
      skip: true  # [r_base in ("4.1", "4.2") or cuda_compiler == "None"]
    requirements:
      host:
        - r-base
        - {{ pin_subpackage('r-xgboost', exact=True) }}
        - r-xgboost =*={{ string_prefix }}_r*h*_{{ PKG_BUILDNUM }}
      run:
        - r-base
        - {{ pin_subpackage('r-xgboost', exact=True) }}
        - r-xgboost =*={{ string_prefix }}_r*h*_{{ PKG_BUILDNUM }}
        - __cuda  # [cuda_compiler != "None"]
    test:
      requires:
        - r-base
      commands:
        - $R -e "library('xgboost')"           # [unix]
        - "\"%R%\" -e \"library('xgboost')\""  # [win]

about:
  home: https://github.com/dmlc/xgboost
  license: Apache-2.0
  license_file: LICENSE
  summary: |
    Scalable, Portable and Distributed Gradient Boosting (GBDT, GBRT or GBM) Library, for
    Python, R, Java, Scala, C++ and more. Runs on single machine, Hadoop, Spark, Flink
    and DataFlow
  description: |
    XGBoost is an optimized distributed gradient boosting library designed to be highly efficient,
    flexible and portable. It implements machine learning algorithms under the Gradient Boosting
    framework. XGBoost provides a parallel tree boosting (also known as GBDT, GBM) that solve many
    data science problems in a fast and accurate way. The same code runs on major distributed
    environment (Hadoop, SGE, MPI) and can solve problems beyond billions of examples.
  doc_url: https://xgboost.readthedocs.io/
  dev_url: https://github.com/dmlc/xgboost/

extra:
  feedstock-name: xgboost
  recipe-maintainers:
    - trivialfis
    - hcho3
    - aldanor
    - danielnachun
    - fhoehle
    - jakirkham
    - ksangeek
    - xhochy
    - mfansler
